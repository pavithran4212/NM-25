{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4z2RoYJxjup",
        "outputId": "bfa37a67-e523-4922-c690-6b07beec2d77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from glob import glob\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import random\n",
        "from PIL import Image\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import os\n",
        "import pandas as pd\n",
        "from skimage import io\n",
        "import torch\n",
        "import torch.nn as nn  # All neural network modules, nn.Linear, nn.Conv2d, BatchNorm, Loss functions\n",
        "import torch.optim as optim  # For all Optimization algorithms, SGD, Adam, etc.\n",
        "import torchvision.transforms as transforms  # Transformations we can perform on our dataset\n",
        "import torchvision\n",
        "from torch.utils.data import (Dataset, DataLoader)  # Gives easier dataset managment and creates mini batches\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.models as models"
      ],
      "metadata": {
        "id": "jZ-9X-HUyL3O"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "animals_list = os.listdir(\"/content/gdrive/My Drive/oregon_wildlife\")\n",
        "animals_file_list = []\n",
        "\n",
        "for i in range(len(animals_list)):\n",
        "\n",
        "  animals_file_list.append(os.listdir(str(\"/content/gdrive/My Drive/oregon_wildlife/\" + animals_list[i])))\n",
        "  n = len(animals_file_list[i])\n",
        "  print('There are', n , animals_list[i] , 'images.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "DVVMabAk2glO",
        "outputId": "fefd900a-8516-4f54-b226-f033a29fb06e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/gdrive/My Drive/oregon_wildlife'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-1f91be474b96>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0manimals_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/gdrive/My Drive/oregon_wildlife\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0manimals_file_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manimals_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/gdrive/My Drive/oregon_wildlife'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w=10\n",
        "h=10\n",
        "fig=plt.figure(figsize=(16, 16))\n",
        "columns = 4\n",
        "rows = 5\n",
        "\n",
        "for i in range(1, len(animals_list)+1):\n",
        "    img = mpimg.imread(str(\"/content/gdrive/My Drive/oregon_wildlife/\"+ animals_list[i-1] + \"/\"+ animals_file_list[i-1][0]))\n",
        "    compose = transforms.Compose([transforms.ToPILImage(),transforms.Resize((256,256))])\n",
        "    img = compose(img)\n",
        "    fig.add_subplot(rows, columns, i)\n",
        "    plt.axis('off')\n",
        "    plt.title(animals_list[i-1])\n",
        "    plt.imshow(img)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "il_tVFUs2iSq",
        "outputId": "45d462aa-44b3-4a75-acbf-a223c162d49d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'animals_list' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-8e169b9c1996>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manimals_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmpimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/gdrive/My Drive/oregon_wildlife/\"\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0manimals_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0manimals_file_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mcompose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCompose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToPILImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'animals_list' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x1600 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir = '/content/gdrive/My Drive/oregon_wildlife'\n",
        "files = [f for f in glob(dir + \"**/**\", recursive=True)] # create a list will allabsolute path of all files"
      ],
      "metadata": {
        "id": "vwpkx-g22lOw"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_animals = pd.DataFrame({\"file_path\":files}) # transform in a dataframe\n",
        "df_animals['animal'] = df_animals['file_path'].str.extract('/oregon_wildlife/(.+)/') # extract the name of the animal\n",
        "df_animals['file'] = df_animals['file_path'].str.extract('oregon_wildlife/.+/(.+)') # extrat the file name\n",
        "df_animals = df_animals.dropna() # drop nas"
      ],
      "metadata": {
        "id": "UU4Td5I_2ojk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "animal_set = set(df_animals['animal'])\n",
        "train_val_test_list = [0,1,2]\n",
        "train_val_weights = [70,15,15]\n",
        "df_animals['train_val_test'] = 'NA'\n",
        "\n",
        "for an in animal_set:\n",
        "  n = sum(df_animals['animal'] == an) # count the number of animals\n",
        "  train_val_test = random.choices(train_val_test_list, weights= train_val_weights,  k=n)\n",
        "  df_animals.loc[df_animals['animal'] == an, 'train_val_test'] = train_val_test"
      ],
      "metadata": {
        "id": "tu1TFT9v2vUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "transform = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'valid': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n"
      ],
      "metadata": {
        "id": "4ngEYpB12yrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_train(path):\n",
        "    return (df_animals[df_animals['file_path'] == path].train_val_test == 0).bool\n",
        "\n",
        "def check_valid(path):\n",
        "    return (df_animals[df_animals['file_path'] == path].train_val_test == 1).bool\n",
        "\n",
        "def check_test(path):\n",
        "    return (df_animals[df_animals['file_path'] == path].train_val_test == 2).bool"
      ],
      "metadata": {
        "id": "wFSS_j_A20Mq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading Dataset\n",
        "image_datasets = {\n",
        "    'train' : ImageFolder(root= dir, transform=transform['train'], is_valid_file=check_train),\n",
        "    'valid' : ImageFolder(root=dir, transform=transform['valid'], is_valid_file=check_valid),\n",
        "    'test' : ImageFolder(root=dir, transform=transform['test'], is_valid_file=check_test)\n",
        "}"
      ],
      "metadata": {
        "id": "zyisPcMk20bh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "num_workers = 0\n",
        "batch_size = 20\n",
        "\n",
        "loaders_scratch = {\n",
        "    'train' : DataLoader(image_datasets['train'], shuffle = True, batch_size = batch_size),\n",
        "    'valid' : DataLoader(image_datasets['valid'], shuffle = True, batch_size = batch_size),\n",
        "    'test' : DataLoader(image_datasets['test'], shuffle = True, batch_size = batch_size)\n",
        "}\n",
        ""
      ],
      "metadata": {
        "id": "jiAxjCwf20oc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# check if CUDA is available\n",
        "use_cuda = torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "gxkIQCwt202u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# define the CNN architecture\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # convolutional layer (sees 224 x 224 x 3 image tensor)\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
        "        # convolutional layer (sees 122 x 122 x 16 tensor)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
        "        # convolutional layer (sees 56 x 56 x 32 tensor)\n",
        "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        # convolutional layer (sees 28 x 28 x 64 tensor)\n",
        "        self.conv4 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        # convolutional layer (sees 14 x 14 x 128 tensor)\n",
        "        self.conv5 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "\n",
        "        # max pooling layer\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        # dropout layer (p=0.25)\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "\n",
        "        self.conv_bn1 = nn.BatchNorm2d(224,3)\n",
        "        self.conv_bn2 = nn.BatchNorm2d(16)\n",
        "        self.conv_bn3 = nn.BatchNorm2d(32)\n",
        "        self.conv_bn4 = nn.BatchNorm2d(64)\n",
        "        self.conv_bn5 = nn.BatchNorm2d(128)\n",
        "        self.conv_bn6 = nn.BatchNorm2d(256)\n",
        "\n",
        "        # linear layer (64 * 4 * 4 -> 133)\n",
        "        self.fc1 = nn.Linear(256 * 7 * 7, 512)\n",
        "        # linear layer (133 -> 133)\n",
        "        self.fc2 = nn.Linear(512, 20)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # add sequence of convolutional and max pooling layers\n",
        "        x = self.conv_bn2(self.pool(F.relu(self.conv1(x))))\n",
        "        x = self.conv_bn3(self.pool(F.relu(self.conv2(x))))\n",
        "        x = self.conv_bn4(self.pool(F.relu(self.conv3(x))))\n",
        "        x = self.conv_bn5(self.pool(F.relu(self.conv4(x))))\n",
        "        x = self.conv_bn6(self.pool(F.relu(self.conv5(x))))\n",
        "        # flatten image input\n",
        "        x = x.view(-1, 256 * 7 * 7)\n",
        "        # add dropout layer\n",
        "        x = self.dropout(x)\n",
        "        # add 1st hidden layer, with relu activation function\n",
        "        x = F.relu(self.fc1(x))\n",
        "        # add dropout layer\n",
        "        x = self.dropout(x)\n",
        "        # add 2nd hidden layer, with relu activation function\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "#-#-# You so NOT have to modify the code below this line. #-#-#\n",
        "\n",
        "# instantiate the CNN\n",
        "model_scratch = Net()\n",
        "print(model_scratch)\n",
        "\n",
        "# move tensors to GPU if CUDA is available\n",
        "if use_cuda:\n",
        "    model_scratch.cuda()"
      ],
      "metadata": {
        "id": "ZHNCAYmF21EF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# specify loss function\n",
        "criterion_scratch = nn.CrossEntropyLoss()\n",
        "\n",
        "# specify optimizer\n",
        "optimizer_scratch = optim.SGD(model_scratch.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "9pHwT10o3DIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path):\n",
        "\n",
        "    \"\"\"returns trained model\"\"\"\n",
        "    # initialize tracker for minimum validation loss\n",
        "    valid_loss_min = np.Inf\n",
        "\n",
        "    for epoch in range(1, n_epochs+1):\n",
        "        # initialize variables to monitor training and validation loss\n",
        "        train_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "\n",
        "        ###################\n",
        "        # train the model #\n",
        "        ###################\n",
        "        model.train()\n",
        "        for batch_idx, (data, target) in enumerate(loaders['train']):\n",
        "            # move to GPU\n",
        "            if use_cuda:\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "            ## find the loss and update the model parameters accordingly\n",
        "            ## record the average training loss, using something like\n",
        "            ## train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
        "            optimizer.zero_grad()\n",
        "            # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            output = model(data)\n",
        "            # calculate the batch loss\n",
        "            loss = criterion(output, target)\n",
        "            # backward pass: compute gradient of the loss with respect to model parameters\n",
        "            loss.backward()\n",
        "            # perform a single optimization step (parameter update)\n",
        "            optimizer.step()\n",
        "            # update training loss\n",
        "            ## record the average training loss, using something like\n",
        "            train_loss = train_loss + (1 / (batch_idx + 1)) * (loss.data - train_loss)\n",
        "\n",
        "\n",
        "        ######################\n",
        "        # validate the model #\n",
        "        ######################\n",
        "        model.eval()\n",
        "        for batch_idx, (data, target) in enumerate(loaders['valid']):\n",
        "            # move to GPU\n",
        "            if use_cuda:\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "            ## update the average validation loss\n",
        "            # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            output = model(data)\n",
        "            # calculate the batch loss\n",
        "            loss = criterion(output, target)\n",
        "            # update average validation loss\n",
        "            valid_loss = valid_loss + (1 / (batch_idx + 1)) * (loss.data - valid_loss)\n",
        "\n",
        "\n",
        "        # print training/validation statistics\n",
        "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "            epoch,\n",
        "            train_loss,\n",
        "            valid_loss\n",
        "            ))\n",
        "\n",
        "        ## TODO: save the model if validation loss has decreased\n",
        "        if valid_loss <= valid_loss_min:\n",
        "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "            valid_loss_min,\n",
        "            valid_loss))\n",
        "            torch.save(model.state_dict(), '/content/gdrive/My Drive/model_scratch.pt')\n",
        "            valid_loss_min = valid_loss\n",
        "\n",
        "    # return trained model\n",
        "    return model\n",
        "\n",
        "# train the model\n",
        "model_scratch = train(25, loaders_scratch, model_scratch, optimizer_scratch, criterion_scratch, use_cuda, 'model_scratch.pt')\n",
        "\n",
        "# load the model that got the best validation accuracy\n",
        "model_scratch.load_state_dict(torch.load('/content/gdrive/My Drive/model_scratch.pt'))\n",
        ""
      ],
      "metadata": {
        "id": "h7WOsNgL3DY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(loaders, model, criterion, use_cuda):\n",
        "\n",
        "    # monitor test loss and accuracy\n",
        "    test_loss = 0.\n",
        "    correct = 0.\n",
        "    total = 0.\n",
        "\n",
        "    model.eval()\n",
        "    if torch.cuda.is_available():\n",
        "      model.cuda()\n",
        "    for batch_idx, (data, target) in enumerate(loaders['test']):\n",
        "        # move to GPU\n",
        "        if use_cuda:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "        # calculate the loss\n",
        "        loss = criterion(output, target)\n",
        "        # update average test loss\n",
        "        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
        "        # convert output probabilities to predicted class\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        # compare predictions to true label\n",
        "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
        "        total += data.size(0)\n",
        "\n",
        "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "\n",
        "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n",
        "        100. * correct / total, correct, total))\n",
        "\n",
        "# call test function\n",
        "test(loaders_scratch, model_scratch, criterion_scratch, use_cuda)"
      ],
      "metadata": {
        "id": "CkXj88GD3D-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "## TODO: Specify data loaders\n",
        "loaders_transfer = loaders_scratch\n",
        ""
      ],
      "metadata": {
        "id": "Tar_L16z3D6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "\n",
        "model_transfer = models.vgg16(pretrained=True)\n",
        "\n",
        "for param in model_transfer.features.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "n_inputs = model_transfer.classifier[6].in_features\n",
        "last_layer = nn.Linear(n_inputs, 133)\n",
        "model_transfer.classifier[6] = last_layer\n",
        "\n",
        "\n",
        "# if GPU is available, move the model to GPU\n",
        "if use_cuda:\n",
        "    model_transfer.cuda()\n",
        "print(model_transfer)"
      ],
      "metadata": {
        "id": "dW3N1VRl3DzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion_transfer = nn.CrossEntropyLoss()\n",
        "optimizer_transfer = optim.SGD(model_transfer.classifier.parameters(), lr=0.001)\n",
        ""
      ],
      "metadata": {
        "id": "iw85P3m93DqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### TODO: Write a function that takes a path to an image as input\n",
        "### and returns the animal that is predicted by the model.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from torch.autograd import Variable\n",
        "import random\n",
        "import re\n",
        "\n",
        "# create a list with a class names\n",
        "class_names = image_datasets['train'].classes\n",
        "class_names = [re.sub(\"\\d{3}.\", \"\", item) for item in class_names]\n",
        "class_names = [re.sub(\"_\", \" \", item) for item in class_names]\n",
        "\n",
        "def predict_breed_transfer(img_path):\n",
        "\n",
        "    # load the image and return the predicted breed\n",
        "    img = Image.open(img_path) # Load the image from provided path\n",
        "\n",
        "    normalize = transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "\n",
        "    preprocess = transforms.Compose([\n",
        "        transforms.Resize(224),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        normalize]\n",
        "    )\n",
        "\n",
        "    img_tensor = preprocess(img).float()\n",
        "    img_tensor.unsqueeze_(0)  # Insert the new axis at index 0 i.e. in front of the other axes/dims.\n",
        "    img_tensor = Variable(img_tensor) #The input to the network needs to be an autograd Variable\n",
        "\n",
        "    if use_cuda:\n",
        "        img_tensor = Variable(img_tensor.cuda())\n",
        "\n",
        "    model_transfer.eval()\n",
        "    output = model_transfer(img_tensor) # Returns a Tensor of shape (batch, num class labels)\n",
        "    output = output.cpu()\n",
        "\n",
        "    # Our prediction will be the index of the class label with the largest value.\n",
        "    predict_index = output.data.numpy().argmax()\n",
        "\n",
        "    predicted_breed = class_names[predict_index]\n",
        "    true_breed = image_datasets['train'].classes[predict_index]\n",
        "\n",
        "    return (predicted_breed, true_breed)\n",
        "\n",
        "# Create list of test image paths\n",
        "test_img_paths = list(df_animals[df_animals.train_val_test == 2].file_path)\n",
        "np.random.shuffle(test_img_paths)\n",
        "\n",
        "for img_path in test_img_paths[0:20]:\n",
        "    predicted_breed, true_breed = predict_breed_transfer(img_path)\n",
        "    print(\"Predicted Animal:\" , predicted_breed, \"\\n\", \"True Animal:\" , true_breed)\n",
        "    img=mpimg.imread(img_path)\n",
        "    imgplot = plt.imshow(img)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "Ra92OVtI3Tyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Predicted Animal: sea lions\n",
        " True Animal: sea_lions\n",
        "\n",
        "Predicted Animal: bald eagle\n",
        " True Animal: bald_eagle\n",
        "\n",
        "Predicted Animal: columbian black-tailed deer"
      ],
      "metadata": {
        "id": "bQhZx1Nd3Tu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1fMck1jO3TsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JGfwffzJ3ToT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_fcJqo-b3Tlf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}